#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import subprocess
import argparse
import json
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich import print as rprint

# åˆ›å»ºæ§åˆ¶å°å¯¹è±¡
console = Console()

def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 0:
        return "0:00.000"
    
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = seconds % 60
    
    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:06.3f}"
    else:
        return f"{minutes}:{secs:06.3f}"

def get_video_duration(video_path):
    """è·å–è§†é¢‘æ—¶é•¿"""
    try:
        cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-print_format', 'json',
            '-show_format',
            video_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0:
            info = json.loads(result.stdout)
            duration = float(info['format']['duration'])
            return duration
        else:
            rprint(f"[red]âŒ è·å–è§†é¢‘æ—¶é•¿å¤±è´¥[/red]")
            return None
            
    except Exception as e:
        rprint(f"[red]âŒ è·å–è§†é¢‘æ—¶é•¿é”™è¯¯: {e}[/red]")
        return None

def check_demucs_installation():
    """æ£€æŸ¥Demucsæ˜¯å¦å®‰è£…"""
    try:
        result = subprocess.run(['python', '-c', 'import demucs'], 
                              capture_output=True, text=True, timeout=10)
        return result.returncode == 0
    except:
        return False

def extract_video_segment(input_path, start_time, duration, output_path):
    """æå–è§†é¢‘ç‰‡æ®µ"""
    rprint(f"[cyan]âœ‚ï¸ æå–è§†é¢‘ç‰‡æ®µ: {format_time(start_time)} - {format_time(start_time + duration)}[/cyan]")
    
    cmd = [
        'ffmpeg',
        '-i', input_path,
        '-ss', str(start_time),
        '-t', str(duration),
        '-c', 'copy',
        output_path,
        '-y'
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True, timeout=60)
        rprint(f"[green]âœ“ è§†é¢‘ç‰‡æ®µæå–å®Œæˆ: {os.path.basename(output_path)}[/green]")
        return True
    except Exception as e:
        rprint(f"[red]âŒ è§†é¢‘ç‰‡æ®µæå–å¤±è´¥: {e}[/red]")
        return False

def extract_audio_from_video(video_path, output_audio_path):
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    rprint(f"[cyan]ğŸµ æå–éŸ³é¢‘: {os.path.basename(video_path)} -> {os.path.basename(output_audio_path)}[/cyan]")
    
    cmd = [
        'ffmpeg',
        '-i', video_path,
        '-vn',
        '-acodec', 'libmp3lame',
        '-ab', '192k',
        '-ar', '44100',
        output_audio_path,
        '-y'
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True, timeout=30)
        rprint(f"[green]âœ“ éŸ³é¢‘æå–å®Œæˆ: {os.path.basename(output_audio_path)}[/green]")
        return True
    except Exception as e:
        rprint(f"[red]âŒ éŸ³é¢‘æå–å¤±è´¥: {e}[/red]")
        return False

def separate_vocals_with_demucs(audio_path, output_dir):
    """ä½¿ç”¨Demucsåˆ†ç¦»äººå£°"""
    rprint(f"[cyan]ğŸ¤ ä½¿ç”¨Demucsåˆ†ç¦»äººå£°: {os.path.basename(audio_path)}[/cyan]")
    
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(output_dir, "demucs_temp")
        os.makedirs(temp_dir, exist_ok=True)
        
        # è¿è¡ŒDemucs
        cmd = [
            'python', '-m', 'demucs.separate',
            '--two-stems=vocals',
            '-o', temp_dir,
            audio_path
        ]
        
        with console.status("[yellow]ğŸ¤ åˆ†ç¦»äººå£°ä¸­...", spinner="dots"):
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
            audio_name = os.path.splitext(os.path.basename(audio_path))[0]
            vocals_path = None
            no_vocals_path = None
            
            # æœç´¢è¾“å‡ºæ–‡ä»¶
            for root, dirs, files in os.walk(temp_dir):
                for file in files:
                    if 'vocals' in file and audio_name in file:
                        vocals_path = os.path.join(root, file)
                    elif 'no_vocals' in file and audio_name in file:
                        no_vocals_path = os.path.join(root, file)
            
            if vocals_path:
                # ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
                final_vocals_path = os.path.join(output_dir, f"{audio_name}_vocals.mp3")
                final_no_vocals_path = os.path.join(output_dir, f"{audio_name}_no_vocals.mp3")
                
                # è½¬æ¢ä¸ºmp3æ ¼å¼
                if vocals_path.endswith('.wav'):
                    subprocess.run([
                        'ffmpeg', '-i', vocals_path, 
                        '-acodec', 'libmp3lame', final_vocals_path, '-y'
                    ], capture_output=True)
                else:
                    subprocess.run(['cp', vocals_path, final_vocals_path])
                
                if no_vocals_path and no_vocals_path.endswith('.wav'):
                    subprocess.run([
                        'ffmpeg', '-i', no_vocals_path,
                        '-acodec', 'libmp3lame', final_no_vocals_path, '-y'
                    ], capture_output=True)
                elif no_vocals_path:
                    subprocess.run(['cp', no_vocals_path, final_no_vocals_path])
                
                rprint(f"[green]âœ“ äººå£°åˆ†ç¦»å®Œæˆ:[/green]")
                rprint(f"  [cyan]ğŸ¤ äººå£°: {os.path.basename(final_vocals_path)}[/cyan]")
                rprint(f"  [cyan]ğŸµ ä¼´å¥: {os.path.basename(final_no_vocals_path)}[/cyan]")
                
                return final_vocals_path, final_no_vocals_path
            else:
                rprint(f"[red]âŒ æœªæ‰¾åˆ°äººå£°åˆ†ç¦»è¾“å‡ºæ–‡ä»¶[/red]")
                return None, None
        else:
            rprint(f"[red]âŒ Demucsåˆ†ç¦»å¤±è´¥: {result.stderr}[/red]")
            return None, None
            
    except Exception as e:
        rprint(f"[red]âŒ äººå£°åˆ†ç¦»é”™è¯¯: {e}[/red]")
        return None, None

def generate_cut_segments(cut_points, total_duration):
    """æ ¹æ®åˆ‡åˆ†ç‚¹ç”Ÿæˆæ®µè½ä¿¡æ¯"""
    segments = []
    
    # ç¬¬ä¸€ä¸ªæ®µè½ï¼šä»å¼€å§‹åˆ°ç¬¬ä¸€ä¸ªåˆ‡åˆ†ç‚¹
    if cut_points:
        segments.append({
            'index': 1,
            'start': 0,
            'end': cut_points[0]['actual'],
            'duration': cut_points[0]['actual'],
            'cut_type': 'start'
        })
        
        # ä¸­é—´æ®µè½
        for i in range(len(cut_points) - 1):
            segments.append({
                'index': i + 2,
                'start': cut_points[i]['actual'],
                'end': cut_points[i + 1]['actual'],
                'duration': cut_points[i + 1]['actual'] - cut_points[i]['actual'],
                'cut_type': 'middle'
            })
        
        # æœ€åä¸€ä¸ªæ®µè½ï¼šä»æœ€åä¸€ä¸ªåˆ‡åˆ†ç‚¹åˆ°ç»“æŸ
        segments.append({
            'index': len(cut_points) + 1,
            'start': cut_points[-1]['actual'],
            'end': total_duration,
            'duration': total_duration - cut_points[-1]['actual'],
            'cut_type': 'end'
        })
    else:
        # æ²¡æœ‰åˆ‡åˆ†ç‚¹ï¼Œæ•´ä¸ªè§†é¢‘ä½œä¸ºä¸€ä¸ªæ®µè½
        segments.append({
            'index': 1,
            'start': 0,
            'end': total_duration,
            'duration': total_duration,
            'cut_type': 'whole'
        })
    
    return segments

def detect_silence_fixed(audio_path, noise_db=-25, min_duration=0.1):
    """ä¿®å¤çš„é™éŸ³æ£€æµ‹å‡½æ•°"""
    rprint(f"[cyan]ğŸ” æ£€æµ‹é™éŸ³æ®µ ({noise_db}dB, â‰¥{min_duration}s)...[/cyan]")
    
    cmd = [
        'ffmpeg',
        '-i', audio_path,
        '-af', f'silencedetect=noise={noise_db}dB:duration={min_duration}',
        '-f', 'null',
        '-',
        '-v', 'info'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        silence_periods = []
        current_silence_start = None
        
        for line in result.stderr.split('\n'):
            line = line.strip()
            
            # è§£æ silence_start
            if 'silence_start:' in line:
                try:
                    start_part = line.split('silence_start:')[1].strip()
                    silence_start = float(start_part.split()[0])
                    current_silence_start = silence_start
                except Exception:
                    continue
            
            # è§£æ silence_end
            elif 'silence_end:' in line and current_silence_start is not None:
                try:
                    parts = line.split('silence_end:')[1]
                    
                    if '|' in parts:
                        end_part = parts.split('|')[0].strip()
                        duration_part = parts.split('silence_duration:')[1].strip()
                        silence_end = float(end_part)
                        silence_duration = float(duration_part)
                    else:
                        silence_end = float(parts.strip())
                        silence_duration = silence_end - current_silence_start
                    
                    if silence_duration >= min_duration:
                        silence_periods.append({
                            'start': current_silence_start,
                            'end': silence_end,
                            'duration': silence_duration,
                            'center': (current_silence_start + silence_end) / 2
                        })
                    
                    current_silence_start = None
                    
                except Exception:
                    continue
        
        if silence_periods:
            rprint(f"[green]âœ“ æ‰¾åˆ° {len(silence_periods)} ä¸ªé™éŸ³æ®µ ({noise_db}dB, â‰¥{min_duration}s)[/green]")
            
            # æŒ‰æ—¶é•¿åˆ†ç±»
            short_silences = [s for s in silence_periods if 0.1 <= s['duration'] < 0.5]
            medium_silences = [s for s in silence_periods if 0.5 <= s['duration'] < 1.0]
            long_silences = [s for s in silence_periods if s['duration'] >= 1.0]
            
            rprint(f"  [dim]çŸ­é™éŸ³(0.1-0.5s): {len(short_silences)} | "
                  f"ä¸­é™éŸ³(0.5-1.0s): {len(medium_silences)} | "
                  f"é•¿é™éŸ³(1.0s+): {len(long_silences)}[/dim]")
            
            # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            for i, period in enumerate(silence_periods[:10]):
                silence_type = "ğŸ”¸" if period['duration'] < 0.5 else "ğŸ”¹" if period['duration'] < 1.0 else "ğŸ”¶"
                rprint(f"  {silence_type} {i+1:2d}. {format_time(period['start'])} - {format_time(period['end'])} "
                      f"({period['duration']:.3f}s) ä¸­ç‚¹: {format_time(period['center'])}")
            
            if len(silence_periods) > 10:
                rprint(f"  ... è¿˜æœ‰ {len(silence_periods) - 10} ä¸ªé™éŸ³æ®µ")
        else:
            rprint(f"[yellow]âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é™éŸ³æ®µ ({noise_db}dB, â‰¥{min_duration}s)[/yellow]")
        
        return silence_periods
        
    except Exception as e:
        rprint(f"[red]âŒ é™éŸ³æ£€æµ‹å¤±è´¥: {e}[/red]")
        return []

def detect_speech_pauses_fixed(audio_path, audio_type="éŸ³é¢‘"):
    """ä¿®å¤çš„äººå£°åœé¡¿æ£€æµ‹"""
    rprint(f"[cyan]ğŸ¤ æ£€æµ‹{audio_type}ä¸­çš„äººå£°åœé¡¿...[/cyan]")
    
    # ç²¾ç»†å‚æ•°é…ç½®
    speech_configs = [
        (-15, 0.05, "è¯é—´åœé¡¿(-15dB, 50ms)", "è¯é—´"),
        (-18, 0.05, "çŸ­å¥åœé¡¿(-18dB, 50ms)", "çŸ­å¥"),
        (-20, 0.05, "å¥é—´åœé¡¿(-20dB, 50ms)", "å¥é—´"),
        (-25, 0.05, "æ®µè½åœé¡¿(-25dB, 50ms)", "æ®µè½"),
        (-15, 0.1, "è¯é—´åœé¡¿(-15dB, 100ms)", "è¯é—´"),
        (-18, 0.1, "çŸ­å¥åœé¡¿(-18dB, 100ms)", "çŸ­å¥"),
        (-20, 0.1, "å¥é—´åœé¡¿(-20dB, 100ms)", "å¥é—´"),
        (-25, 0.1, "æ®µè½åœé¡¿(-25dB, 100ms)", "æ®µè½"),
        (-15, 0.15, "é•¿è¯é—´(-15dB, 150ms)", "é•¿è¯é—´"),
        (-18, 0.15, "é•¿å¥é—´(-18dB, 150ms)", "é•¿å¥é—´"),
        (-20, 0.15, "è‡ªç„¶åœé¡¿(-20dB, 150ms)", "è‡ªç„¶"),
    ]
    
    all_results = []
    
    for noise_db, min_duration, desc, pause_type in speech_configs:
        cmd = [
            'ffmpeg',
            '-i', audio_path,
            '-af', f'silencedetect=noise={noise_db}dB:duration={min_duration}',
            '-f', 'null',
            '-',
            '-v', 'info'
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
            
            silence_periods = []
            current_silence_start = None
            
            for line in result.stderr.split('\n'):
                line = line.strip()
                
                if 'silence_start:' in line:
                    try:
                        start_part = line.split('silence_start:')[1].strip()
                        silence_start = float(start_part.split()[0])
                        current_silence_start = silence_start
                    except:
                        continue
                        
                elif 'silence_end:' in line and current_silence_start is not None:
                    try:
                        parts = line.split('silence_end:')[1]
                        
                        if '|' in parts:
                            end_part = parts.split('|')[0].strip()
                            duration_part = parts.split('silence_duration:')[1].strip()
                            silence_end = float(end_part)
                            silence_duration = float(duration_part)
                        else:
                            silence_end = float(parts.strip())
                            silence_duration = silence_end - current_silence_start
                        
                        if silence_duration >= min_duration:
                            silence_periods.append({
                                'start': current_silence_start,
                                'end': silence_end,
                                'duration': silence_duration,
                                'center': (current_silence_start + silence_end) / 2,
                                'type': pause_type
                            })
                        current_silence_start = None
                    except:
                        continue
            
            # æŒ‰åœé¡¿æ—¶é•¿åˆ†ç±»
            micro_pauses = [s for s in silence_periods if 0.05 <= s['duration'] < 0.1]
            short_pauses = [s for s in silence_periods if 0.1 <= s['duration'] < 0.2]
            medium_pauses = [s for s in silence_periods if 0.2 <= s['duration'] < 0.5]
            long_pauses = [s for s in silence_periods if s['duration'] >= 0.5]
            
            result_info = {
                'config': (noise_db, min_duration, desc, pause_type),
                'silences': silence_periods,
                'count': len(silence_periods),
                'micro': len(micro_pauses),
                'short': len(short_pauses),
                'medium': len(medium_pauses),
                'long': len(long_pauses)
            }
            all_results.append(result_info)
            
            if silence_periods:
                rprint(f"  [green]âœ“ {desc}: {len(silence_periods):3d} ä¸ªåœé¡¿[/green] "
                      f"[dim](å¾®:{len(micro_pauses)} çŸ­:{len(short_pauses)} ä¸­:{len(medium_pauses)} é•¿:{len(long_pauses)})[/dim]")
                
                # æ˜¾ç¤ºå‰3ä¸ªåœé¡¿
                for i, period in enumerate(silence_periods[:3]):
                    if period['duration'] < 0.1:
                        icon = "ğŸ”¸"
                    elif period['duration'] < 0.2:
                        icon = "ğŸ”¹"
                    elif period['duration'] < 0.5:
                        icon = "ğŸ”·"
                    else:
                        icon = "ğŸ”¶"
                    
                    rprint(f"    {icon} {i+1}. {format_time(period['start'])} - {format_time(period['end'])} "
                          f"({period['duration']*1000:5.0f}ms) [{period['type']}]")
                
                if len(silence_periods) > 3:
                    rprint(f"    ... è¿˜æœ‰ {len(silence_periods) - 3} ä¸ªåœé¡¿")
            else:
                rprint(f"  [red]âœ— {desc}: 0 ä¸ªåœé¡¿[/red]")
                
        except Exception as e:
            rprint(f"  [red]âœ— {desc}: æ£€æµ‹å¤±è´¥ - {e}[/red]")
    
    return all_results

def find_optimal_speech_cuts_fixed(all_results, target_interval_minutes=30, total_duration=None):
    """ä»äººå£°åœé¡¿ä¸­æ‰¾åˆ°æœ€ä½³åˆ‡åˆ†ç‚¹"""
    rprint(f"\n[cyan]ğŸ¯ ä»äººå£°åœé¡¿ä¸­å¯»æ‰¾{target_interval_minutes}åˆ†é’Ÿé—´éš”çš„æœ€ä½³åˆ‡åˆ†ç‚¹...[/cyan]")
    
    if not total_duration:
        rprint("[red]âŒ éœ€è¦æä¾›æ€»æ—¶é•¿[/red]")
        return []
    
    # é€‰æ‹©æœ€ä½³çš„æ£€æµ‹ç»“æœ
    best_result = None
    
    for result in all_results:
        count = result['count']
        config = result['config']
        
        if count >= 3:  # è‡³å°‘è¦æœ‰3ä¸ªåœé¡¿
            score = 0
            
            # åŸºç¡€åˆ†æ•°
            if 5 <= count <= 30:
                score += 10
            elif count >= 3:
                score += 5
            
            # åœé¡¿ç±»å‹åŠ åˆ†
            score += result['short'] * 2
            score += result['medium'] * 1.5
            score += result['micro'] * 1
            
            # å™ªéŸ³é˜ˆå€¼åŠ åˆ†
            if config[0] >= -20:
                score += 3
            elif config[0] >= -25:
                score += 2
            
            # æ—¶é•¿åŠ åˆ†
            if 0.05 <= config[1] <= 0.15:
                score += 3
            elif 0.05 <= config[1] <= 0.2:
                score += 2
            
            result['score'] = score
            
            if best_result is None or score > best_result['score']:
                best_result = result
    
    if not best_result:
        rprint("[red]âŒ æœªæ‰¾åˆ°åˆé€‚çš„åœé¡¿æ£€æµ‹ç»“æœ[/red]")
        return []
    
    config = best_result['config']
    silences = best_result['silences']
    
    rprint(f"[green]ğŸ† é€‰æ‹©æœ€ä½³é…ç½®: {config[2]} (è¯„åˆ†: {best_result['score']:.1f})[/green]")
    rprint(f"[yellow]ğŸ“Š åœé¡¿ç»Ÿè®¡: æ€»è®¡{len(silences)}ä¸ª | "
          f"å¾®åœé¡¿{best_result['micro']}ä¸ª | çŸ­åœé¡¿{best_result['short']}ä¸ª | "
          f"ä¸­åœé¡¿{best_result['medium']}ä¸ª | é•¿åœé¡¿{best_result['long']}ä¸ª[/yellow]")
    
    # è®¡ç®—ç›®æ ‡åˆ‡åˆ†ç‚¹
    target_seconds = target_interval_minutes * 60
    target_points = []
    
    current = target_seconds
    while current < total_duration - 60:
        target_points.append(current)
        current += target_seconds
    
    if not target_points:
        rprint(f"[yellow]âš ï¸ éŸ³é¢‘æ—¶é•¿ä¸è¶³ä»¥æŒ‰{target_interval_minutes}åˆ†é’Ÿåˆ‡åˆ†[/yellow]")
        return []
    
    rprint(f"[yellow]ğŸ¯ ç›®æ ‡åˆ‡åˆ†ç‚¹: {len(target_points)} ä¸ª[/yellow]")
    
    cut_points = []
    
    for i, target_point in enumerate(target_points):
        rprint(f"[yellow]ğŸ” åˆ‡åˆ†ç‚¹ {i+1} (ç›®æ ‡: {format_time(target_point)}):[/yellow]")
        
        # åœ¨ç›®æ ‡ç‚¹å‰åå¯»æ‰¾æœ€ä½³åœé¡¿
        search_ranges = [15, 30, 60, 120, 300]
        
        found_cut = False
        
        for search_range in search_ranges:
            if found_cut:
                break
                
            search_start = max(0, target_point - search_range)
            search_end = min(total_duration, target_point + search_range)
            
            # æ‰¾åˆ°èŒƒå›´å†…çš„åœé¡¿
            candidates = []
            for silence in silences:
                if search_start <= silence['center'] <= search_end:
                    distance = abs(silence['center'] - target_point)
                    
                    # è¯„åˆ†ç³»ç»Ÿ
                    duration_score = 1.0
                    if 0.1 <= silence['duration'] <= 0.3:
                        duration_score = 2.0
                    elif 0.05 <= silence['duration'] <= 0.5:
                        duration_score = 1.5
                    
                    distance_score = 1.0 / (distance + 1)
                    
                    type_score = 1.0
                    if silence['type'] in ['å¥é—´', 'è‡ªç„¶', 'æ®µè½']:
                        type_score = 1.5
                    elif silence['type'] in ['çŸ­å¥', 'é•¿å¥é—´']:
                        type_score = 1.3
                    
                    total_score = duration_score * distance_score * type_score
                    
                    candidates.append({
                        'silence': silence,
                        'distance': distance,
                        'score': total_score
                    })
            
            if candidates:
                candidates.sort(key=lambda x: (-x['score'], x['distance']))
                best = candidates[0]
                
                cut_points.append({
                    'target': target_point,
                    'actual': best['silence']['center'],
                    'deviation': best['silence']['center'] - target_point,
                    'silence_start': best['silence']['start'],
                    'silence_end': best['silence']['end'],
                    'silence_duration': best['silence']['duration'],
                    'silence_type': best['silence']['type'],
                    'search_range': search_range,
                    'score': best['score']
                })
                
                rprint(f"  [green]âœ“ æ‰¾åˆ°åœé¡¿: {format_time(best['silence']['center'])} "
                      f"(åå·® {best['silence']['center'] - target_point:+.1f}s, "
                      f"åœé¡¿ {best['silence']['duration']*1000:.0f}ms, "
                      f"ç±»å‹: {best['silence']['type']}, "
                      f"æœç´¢èŒƒå›´ Â±{search_range}s)[/green]")
                
                found_cut = True
            else:
                rprint(f"  [yellow]âš ï¸ Â±{search_range}sèŒƒå›´å†…æ— åˆé€‚åœé¡¿[/yellow]")
        
        if not found_cut:
            fallback_time = min(target_point + 30, total_duration - 30)
            cut_points.append({
                'target': target_point,
                'actual': fallback_time,
                'deviation': fallback_time - target_point,
                'silence_start': fallback_time,
                'silence_end': fallback_time,
                'silence_duration': 0,
                'silence_type': 'fallback',
                'search_range': 0,
                'score': 0
            })
            rprint(f"  [red]âœ— æ— åˆé€‚åœé¡¿ï¼Œä½¿ç”¨å¤‡é€‰ç‚¹ {format_time(fallback_time)}[/red]")
    
    return cut_points

def extract_audio_from_video_large(video_path, output_audio_path, timeout_minutes=10):
    """ä»å¤§è§†é¢‘ä¸­æå–éŸ³é¢‘ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´"""
    rprint(f"[cyan]ğŸµ æå–éŸ³é¢‘ (å¤§æ–‡ä»¶æ¨¡å¼): {os.path.basename(video_path)} -> {os.path.basename(output_audio_path)}[/cyan]")
    
    cmd = [
        'ffmpeg',
        '-i', video_path,
        '-vn',
        '-acodec', 'libmp3lame',
        '-ab', '128k',
        '-ar', '22050',
        '-ac', '1',
        output_audio_path,
        '-y'
    ]
    
    try:
        timeout_seconds = timeout_minutes * 60
        with console.status(f"[yellow]ğŸµ æå–éŸ³é¢‘ä¸­... (æœ€å¤šç­‰å¾…{timeout_minutes}åˆ†é’Ÿ)", spinner="dots"):
            subprocess.run(cmd, check=True, capture_output=True, timeout=timeout_seconds)
        rprint(f"[green]âœ“ éŸ³é¢‘æå–å®Œæˆ: {os.path.basename(output_audio_path)}[/green]")
        return True
    except subprocess.TimeoutExpired:
        rprint(f"[red]âŒ éŸ³é¢‘æå–è¶…æ—¶ï¼ˆ{timeout_minutes}åˆ†é’Ÿï¼‰[/red]")
        return False
    except Exception as e:
        rprint(f"[red]âŒ éŸ³é¢‘æå–å¤±è´¥: {e}[/red]")
        return False

def find_cut_points_from_silences(silences, target_interval_minutes=30, total_duration=None):
    """ä»é™éŸ³æ®µä¸­æ‰¾åˆ°æœ€ä½³åˆ‡åˆ†ç‚¹"""
    rprint(f"[cyan]ğŸ¯ ä»é™éŸ³æ®µä¸­å¯»æ‰¾{target_interval_minutes}åˆ†é’Ÿé—´éš”çš„åˆ‡åˆ†ç‚¹...[/cyan]")
    
    if not total_duration:
        rprint("[red]âŒ éœ€è¦æä¾›æ€»æ—¶é•¿[/red]")
        return []
    
    # è®¡ç®—ç›®æ ‡åˆ‡åˆ†ç‚¹
    target_seconds = target_interval_minutes * 60
    target_points = []
    
    current = target_seconds
    while current < total_duration - 60:
        target_points.append(current)
        current += target_seconds
    
    if not target_points:
        rprint(f"[yellow]âš ï¸ éŸ³é¢‘æ—¶é•¿ä¸è¶³ä»¥æŒ‰{target_interval_minutes}åˆ†é’Ÿåˆ‡åˆ†[/yellow]")
        return []
    
    rprint(f"[yellow]ğŸ¯ ç›®æ ‡åˆ‡åˆ†ç‚¹: {len(target_points)} ä¸ª[/yellow]")
    rprint(f"[yellow]ğŸ“Š å¯ç”¨é™éŸ³æ®µ: {len(silences)} ä¸ª[/yellow]")
    
    cut_points = []
    
    for i, target_point in enumerate(target_points):
        rprint(f"[yellow]ğŸ” åˆ‡åˆ†ç‚¹ {i+1} (ç›®æ ‡: {format_time(target_point)}):[/yellow]")
        
        # åœ¨ç›®æ ‡ç‚¹å‰åå¯»æ‰¾æœ€ä½³é™éŸ³æ®µ
        search_ranges = [30, 60, 120, 300, 600]
        
        found_cut = False
        
        for search_range in search_ranges:
            if found_cut:
                break
                
            search_start = max(0, target_point - search_range)
            search_end = min(total_duration, target_point + search_range)
            
            # æ‰¾åˆ°èŒƒå›´å†…çš„é™éŸ³æ®µ
            candidates = []
            for silence in silences:
                if search_start <= silence['center'] <= search_end:
                    distance = abs(silence['center'] - target_point)
                    # è¯„åˆ†ï¼šé™éŸ³æ—¶é•¿è¶Šé•¿è¶Šå¥½ï¼Œè·ç¦»ç›®æ ‡ç‚¹è¶Šè¿‘è¶Šå¥½
                    score = silence['duration'] / (distance + 1)
                    candidates.append({
                        'silence': silence,
                        'distance': distance,
                        'score': score
                    })
            
            if candidates:
                # æŒ‰è¯„åˆ†æ’åº
                candidates.sort(key=lambda x: (-x['score'], x['distance']))
                best = candidates[0]
                
                cut_points.append({
                    'target': target_point,
                    'actual': best['silence']['center'],
                    'deviation': best['silence']['center'] - target_point,
                    'silence_start': best['silence']['start'],
                    'silence_end': best['silence']['end'],
                    'silence_duration': best['silence']['duration'],
                    'search_range': search_range
                })
                
                rprint(f"  [green]âœ“ åˆ‡åˆ†ç‚¹: {format_time(best['silence']['center'])} "
                      f"(åå·® {best['silence']['center'] - target_point:+.1f}s, "
                      f"é™éŸ³ {best['silence']['duration']:.3f}s, "
                      f"æœç´¢èŒƒå›´ Â±{search_range}s)[/green]")
                
                found_cut = True
            else:
                rprint(f"  [yellow]âš ï¸ Â±{search_range}sèŒƒå›´å†…æ— é™éŸ³æ®µ[/yellow]")
        
        if not found_cut:
            fallback_time = min(target_point + 60, total_duration - 60)
            cut_points.append({
                'target': target_point,
                'actual': fallback_time,
                'deviation': fallback_time - target_point,
                'silence_start': fallback_time,
                'silence_end': fallback_time,
                'silence_duration': 0,
                'search_range': 0,
                'type': 'fallback'
            })
            rprint(f"  [red]âœ— æ— åˆé€‚é™éŸ³æ®µï¼Œä½¿ç”¨å¤‡é€‰ç‚¹ {format_time(fallback_time)}[/red]")
    
    return cut_points

def process_video_segments_25db(input_path, output_dir, segment_duration=30, target_interval=30):
    """å¤„ç†è§†é¢‘ç‰‡æ®µå¹¶åŸºäºäººå£°åœé¡¿æ£€æµ‹åˆ‡åˆ†ç‚¹"""
    
    rprint(Panel.fit("[bold magenta]ğŸš€ åŸºäºäººå£°åœé¡¿çš„æ™ºèƒ½åˆ‡åˆ†å·¥å…· (ä¿®å¤ç‰ˆ)[/bold magenta]", border_style="magenta"))
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(input_path):
        rprint(f"[bold red]âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}[/bold red]")
        return
    
    rprint(f"[green]âœ“ è¾“å…¥æ–‡ä»¶[/green]: [cyan]{os.path.basename(input_path)}[/cyan]")
    
    # è·å–è§†é¢‘ä¿¡æ¯
    total_duration = get_video_duration(input_path)
    if total_duration is None:
        return
    
    rprint(f"[green]âœ“ è§†é¢‘æ€»æ—¶é•¿[/green]: [yellow]{format_time(total_duration)}[/yellow]")
    
    # æ£€æŸ¥Demucs
    if not check_demucs_installation():
        rprint("[red]âŒ Demucsæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install demucs[/red]")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æå–æµ‹è¯•ç‰‡æ®µè¿›è¡Œåˆ†æ
    test_segments = []
    
    # å¼€å¤´ç‰‡æ®µ
    if total_duration > segment_duration:
        test_segments.append({
            'name': 'start',
            'start': 0,
            'duration': segment_duration,
            'desc': f'å¼€å¤´{segment_duration}ç§’'
        })
    
    # ä¸­é—´ç‰‡æ®µ
    if total_duration > segment_duration * 4:
        middle_start = (total_duration - segment_duration) / 2
        test_segments.append({
            'name': 'middle',
            'start': middle_start,
            'duration': segment_duration,
            'desc': f'ä¸­é—´{segment_duration}ç§’'
        })
    
    if not test_segments:
        rprint(f"[red]âŒ è§†é¢‘å¤ªçŸ­ï¼Œæ— æ³•æå–æµ‹è¯•ç‰‡æ®µ[/red]")
        return
    
    rprint(f"[cyan]ğŸ“‹ å°†åˆ†æ {len(test_segments)} ä¸ªæµ‹è¯•ç‰‡æ®µ[/cyan]")
    
    best_vocals_path = None
    
    # å¤„ç†æµ‹è¯•ç‰‡æ®µ
    for segment in test_segments:
        rprint(f"\n[yellow]ğŸ¬ å¤„ç†{segment['desc']}ç‰‡æ®µ...[/yellow]")
        
        # æå–è§†é¢‘ç‰‡æ®µ
        video_segment_path = os.path.join(output_dir, f"segment_{segment['name']}.mp4")
        if not extract_video_segment(input_path, segment['start'], segment['duration'], video_segment_path):
            continue
        
        # æå–éŸ³é¢‘
        audio_path = os.path.join(output_dir, f"segment_{segment['name']}_audio.mp3")
        if not extract_audio_from_video(video_segment_path, audio_path):
            continue
        
        # åˆ†æåŸå§‹éŸ³é¢‘çš„é™éŸ³æ®µ
        rprint(f"[cyan]ğŸ“Š åˆ†æ{segment['desc']}åŸå§‹éŸ³é¢‘çš„é™éŸ³æ®µ:[/cyan]")
        original_silences = detect_silence_fixed(audio_path, noise_db=-25, min_duration=0.1)
        
        # åˆ†ç¦»äººå£°
        vocals_path, no_vocals_path = separate_vocals_with_demucs(audio_path, output_dir)
        
        if vocals_path:
            best_vocals_path = vocals_path
            
            # åˆ†æäººå£°çš„é™éŸ³æ®µ
            rprint(f"[cyan]ğŸ“Š åˆ†æ{segment['desc']}çº¯äººå£°çš„é™éŸ³æ®µ:[/cyan]")
            vocal_silences = detect_silence_fixed(vocals_path, noise_db=-25, min_duration=0.1)
            
            # åˆ†æäººå£°çš„ç²¾ç»†åœé¡¿
            rprint(f"[cyan]ğŸ¤ åˆ†æ{segment['desc']}çº¯äººå£°çš„ç²¾ç»†åœé¡¿:[/cyan]")
            speech_pauses = detect_speech_pauses_fixed(vocals_path, f"{segment['desc']}çº¯äººå£°")
            
            # å¯¹æ¯”åˆ†æ
            rprint(f"[yellow]ğŸ“ˆ å¯¹æ¯”åˆ†æ:[/yellow]")
            rprint(f"  åŸå§‹éŸ³é¢‘é™éŸ³æ®µ: {len(original_silences)} ä¸ª")
            rprint(f"  çº¯äººå£°é™éŸ³æ®µ: {len(vocal_silences)} ä¸ª")
            
            # ç»Ÿè®¡ç²¾ç»†åœé¡¿
            total_speech_pauses = sum(result['count'] for result in speech_pauses)
            rprint(f"  çº¯äººå£°ç²¾ç»†åœé¡¿: {total_speech_pauses} ä¸ª")
            
            if len(vocal_silences) > len(original_silences):
                rprint(f"  [green]âœ“ äººå£°åˆ†ç¦»åæ£€æµ‹åˆ°æ›´å¤šé™éŸ³æ®µ (+{len(vocal_silences) - len(original_silences)})[/green]")
            elif len(vocal_silences) == len(original_silences):
                rprint(f"  [yellow]= é™éŸ³æ®µæ•°é‡ç›¸åŒ[/yellow]")
            else:
                rprint(f"  [red]- äººå£°åˆ†ç¦»åé™éŸ³æ®µå‡å°‘ ({len(vocal_silences) - len(original_silences)})[/red]")
            
            if total_speech_pauses > 0:
                rprint(f"  [green]âœ“ æˆåŠŸæ£€æµ‹åˆ°äººå£°ç²¾ç»†åœé¡¿ï¼[/green]")
            else:
                rprint(f"  [yellow]âš ï¸ æœªæ£€æµ‹åˆ°ç²¾ç»†åœé¡¿[/yellow]")
        
        rprint(f"[green]âœ… {segment['desc']}ç‰‡æ®µåˆ†æå®Œæˆ[/green]")
    
    # å¦‚æœæœ‰äººå£°æ–‡ä»¶ï¼Œè¿›è¡Œå®Œæ•´è§†é¢‘çš„åˆ‡åˆ†ç‚¹åˆ†æ
    if best_vocals_path:
        rprint(f"\n[cyan]ğŸ¯ åŸºäºäººå£°è¿›è¡Œå®Œæ•´è§†é¢‘çš„{target_interval}åˆ†é’Ÿé—´éš”åˆ‡åˆ†åˆ†æ...[/cyan]")
        
        # æå–å®Œæ•´éŸ³é¢‘è¿›è¡Œåˆ†æ
        full_audio_path = os.path.join(output_dir, "full_audio.mp3")
        if extract_audio_from_video_large(input_path, full_audio_path, timeout_minutes=15):
            # åˆ†ç¦»å®Œæ•´éŸ³é¢‘çš„äººå£°
            full_vocals_path, _ = separate_vocals_with_demucs(full_audio_path, output_dir)
            
            if full_vocals_path:
                # å°è¯•ç²¾ç»†åœé¡¿åˆ‡åˆ†
                rprint(f"[cyan]ğŸ¤ å°è¯•åŸºäºäººå£°ç²¾ç»†åœé¡¿è¿›è¡Œåˆ‡åˆ†...[/cyan]")
                speech_results = detect_speech_pauses_fixed(full_vocals_path, "å®Œæ•´äººå£°")
                speech_cut_points = find_optimal_speech_cuts_fixed(speech_results, target_interval, total_duration)
                
                # å¤‡é€‰çš„é™éŸ³æ®µåˆ‡åˆ†
                rprint(f"[cyan]ğŸ” å°è¯•åŸºäºé™éŸ³æ®µè¿›è¡Œåˆ‡åˆ†...[/cyan]")
                silence_cut_points = []
                full_silences = detect_silence_fixed(full_vocals_path, noise_db=-25, min_duration=0.3)
                
                if full_silences:
                    # ä½¿ç”¨é™éŸ³æ®µè¿›è¡Œåˆ‡åˆ†
                    silence_cut_points = find_cut_points_from_silences(full_silences, target_interval, total_duration)
                
                # é€‰æ‹©æœ€ä½³åˆ‡åˆ†æ–¹æ¡ˆ
                final_cut_points = []
                cut_method = ""
                
                if speech_cut_points and len(speech_cut_points) > 0:
                    final_cut_points = speech_cut_points
                    cut_method = "äººå£°ç²¾ç»†åœé¡¿"
                    rprint(f"[green]ğŸ† é€‰æ‹©äººå£°ç²¾ç»†åœé¡¿åˆ‡åˆ†æ–¹æ¡ˆ[/green]")
                elif silence_cut_points and len(silence_cut_points) > 0:
                    final_cut_points = silence_cut_points
                    cut_method = "é™éŸ³æ®µ"
                    rprint(f"[yellow]âš ï¸ ä½¿ç”¨é™éŸ³æ®µåˆ‡åˆ†æ–¹æ¡ˆ[/yellow]")
                else:
                    rprint(f"[red]âŒ ä¸¤ç§åˆ‡åˆ†æ–¹æ¡ˆéƒ½æœªæ‰¾åˆ°åˆé€‚çš„åˆ‡åˆ†ç‚¹[/red]")
                
                if final_cut_points:
                    # ç”Ÿæˆæ®µè½ä¿¡æ¯
                    segments = generate_cut_segments(final_cut_points, total_duration)
                    
                    rprint(f"\n[green]ğŸ‰ ä½¿ç”¨{cut_method}æ‰¾åˆ° {len(final_cut_points)} ä¸ªåˆ‡åˆ†ç‚¹ï¼Œç”Ÿæˆ {len(segments)} ä¸ªæ®µè½:[/green]")
                    
                    total_segments_duration = 0
                    for segment in segments:
                        cut_type_desc = "ç²¾ç»†åœé¡¿" if 'silence_type' in final_cut_points[0] and final_cut_points[0]['silence_type'] != 'fallback' else "é™éŸ³åˆ‡åˆ†" if segment['cut_type'] == 'silence_cut' else "å¤‡é€‰åˆ‡åˆ†" if segment['cut_type'] == 'fallback' else "æœ€ç»ˆæ®µ"
                        rprint(f"  ğŸ“¹ æ®µè½ {segment['index']:2d}: {format_time(segment['start'])} - {format_time(segment['end'])} "
                              f"({format_time(segment['duration'])}) [{cut_type_desc}]")
                        total_segments_duration += segment['duration']
                    
                    rprint(f"\n[cyan]ğŸ“Š åˆ‡åˆ†ç»Ÿè®¡:[/cyan]")
                    rprint(f"  æ€»æ—¶é•¿: {format_time(total_duration)}")
                    rprint(f"  æ®µè½æ€»æ—¶é•¿: {format_time(total_segments_duration)}")
                    rprint(f"  å¹³å‡æ®µè½æ—¶é•¿: {format_time(total_segments_duration / len(segments))}")
                    rprint(f"  åˆ‡åˆ†æ–¹æ³•: {cut_method}")
                    
                    # ä¿å­˜åˆ‡åˆ†ç‚¹ä¿¡æ¯
                    cut_points_file = os.path.join(output_dir, "cut_points_speech_fixed.txt")
                    with open(cut_points_file, 'w', encoding='utf-8') as f:
                        f.write(f"åŸºäº{cut_method}çš„åˆ‡åˆ†ç‚¹ä¿¡æ¯\n")
                        f.write("=" * 50 + "\n\n")
                        
                        f.write("åˆ‡åˆ†ç‚¹è¯¦æƒ…:\n")
                        for i, cp in enumerate(final_cut_points):
                            f.write(f"åˆ‡åˆ†ç‚¹ {i+1}: {format_time(cp['actual'])}\n")
                            f.write(f"  ç›®æ ‡æ—¶é—´: {format_time(cp['target'])}\n")
                            f.write(f"  åå·®: {cp['deviation']:+.1f}s\n")
                            f.write(f"  é™éŸ³æ®µ: {format_time(cp['silence_start'])} - {format_time(cp['silence_end'])}\n")
                            f.write(f"  é™éŸ³æ—¶é•¿: {cp['silence_duration']:.3f}s\n")
                            if 'silence_type' in cp:
                                f.write(f"  åœé¡¿ç±»å‹: {cp['silence_type']}\n")
                            f.write(f"  æœç´¢èŒƒå›´: Â±{cp['search_range']}s\n\n")
                        
                        f.write("ç”Ÿæˆçš„æ®µè½:\n")
                        for segment in segments:
                            f.write(f"æ®µè½ {segment['index']}: {format_time(segment['start'])} - {format_time(segment['end'])} ({format_time(segment['duration'])})\n")
                    
                    rprint(f"[green]âœ“ åˆ‡åˆ†ç‚¹ä¿¡æ¯å·²ä¿å­˜åˆ°: {cut_points_file}[/green]")
                else:
                    rprint("[red]âŒ æœªæ‰¾åˆ°åˆé€‚çš„åˆ‡åˆ†ç‚¹[/red]")
    
    # æ˜¾ç¤ºç»“æœæ€»ç»“
    rprint(Panel(
        f"[bold green]ğŸ‰ åŸºäºäººå£°åœé¡¿çš„æ™ºèƒ½åˆ‡åˆ†åˆ†æå®Œæˆï¼[/bold green]\n\n"
        f"â€¢ åˆ†æç‰‡æ®µ: [blue]{len(test_segments)}[/blue] ä¸ª\n"
        f"â€¢ ç›®æ ‡é—´éš”: [yellow]{target_interval}[/yellow] åˆ†é’Ÿ\n"
        f"â€¢ è¾“å‡ºç›®å½•: [cyan]{output_dir}[/cyan]\n\n"
        f"[dim]ğŸ’¡ ä¼˜å…ˆä½¿ç”¨äººå£°ç²¾ç»†åœé¡¿(50msèµ·)ï¼Œå¤‡é€‰é™éŸ³æ®µåˆ‡åˆ†\n"
        f"ğŸ”¸ å¾®åœé¡¿(50-100ms) ğŸ”¹ çŸ­åœé¡¿(100-200ms) ğŸ”· ä¸­åœé¡¿(200-500ms) ğŸ”¶ é•¿åœé¡¿(500ms+)\n"
        f"ğŸ“‹ åˆ‡åˆ†ç‚¹ä¿¡æ¯å·²ä¿å­˜åˆ° cut_points_speech_fixed.txt[/dim]",
        title="âœ¨ å®Œæˆ",
        border_style="green"
    ))

def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(description="åŸºäºäººå£°åœé¡¿çš„æ™ºèƒ½åˆ‡åˆ†å·¥å…· (ä¿®å¤ç‰ˆ)")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥è§†é¢‘æ–‡ä»¶")
    parser.add_argument("--output", "-o", required=True, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--duration", "-d", type=int, default=30, help="æµ‹è¯•ç‰‡æ®µé•¿åº¦ï¼ˆç§’ï¼‰")
    parser.add_argument("--interval", "-t", type=int, default=30, help="ç›®æ ‡åˆ‡åˆ†é—´éš”ï¼ˆåˆ†é’Ÿï¼‰")
    
    args = parser.parse_args()
    
    process_video_segments_25db(
        input_path=args.input,
        output_dir=args.output,
        segment_duration=args.duration,
        target_interval=args.interval
    )

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        main()
    else:
        # ç›´æ¥è°ƒç”¨ç¤ºä¾‹
        input_video = "/home/darkchunk/code/VideoLingo/output/Learn Solidity Smart Contract Development ï½œ Full 2024 Cyfrin Updraft Course.webm"
        output_directory = "/home/darkchunk/code/VideoLingo/output/test_speech_cuts_fixed"
        
        process_video_segments_25db(
            input_video, 
            output_directory, 
            segment_duration=30,
            target_interval=30  # 30åˆ†é’Ÿé—´éš”
        )