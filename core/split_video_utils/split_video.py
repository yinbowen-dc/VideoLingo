#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import subprocess
import argparse
import json
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich import print as rprint
from rich.prompt import Confirm

# åˆ›å»ºæ§åˆ¶å°å¯¹è±¡
console = Console()

def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 0:
        return "0:00.000"
    
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = seconds % 60
    
    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:06.3f}"
    else:
        return f"{minutes}:{secs:06.3f}"

def get_video_duration(video_path):
    """è·å–è§†é¢‘æ—¶é•¿"""
    try:
        cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-print_format', 'json',
            '-show_format',
            video_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0:
            info = json.loads(result.stdout)
            duration = float(info['format']['duration'])
            return duration
        else:
            rprint(f"[red]âŒ è·å–è§†é¢‘æ—¶é•¿å¤±è´¥[/red]")
            return None
            
    except Exception as e:
        rprint(f"[red]âŒ è·å–è§†é¢‘æ—¶é•¿é”™è¯¯: {e}[/red]")
        return None

def check_demucs_installation():
    """æ£€æŸ¥Demucsæ˜¯å¦å®‰è£…"""
    try:
        result = subprocess.run(['python', '-c', 'import demucs'], 
                              capture_output=True, text=True, timeout=10)
        return result.returncode == 0
    except:
        return False

def extract_video_segment(input_path, start_time, duration, output_path):
    """æå–è§†é¢‘ç‰‡æ®µ"""
    cmd = [
        'ffmpeg',
        '-i', input_path,
        '-ss', str(start_time),
        '-t', str(duration),
        '-c', 'copy',
        output_path,
        '-y'
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True, timeout=60)
        return True
    except Exception as e:
        rprint(f"[red]âŒ è§†é¢‘ç‰‡æ®µæå–å¤±è´¥: {e}[/red]")
        return False

def extract_audio_from_video(video_path, output_audio_path):
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    cmd = [
        'ffmpeg',
        '-i', video_path,
        '-vn',
        '-acodec', 'libmp3lame',
        '-ab', '192k',
        '-ar', '44100',
        output_audio_path,
        '-y'
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True, timeout=30)
        return True
    except Exception as e:
        rprint(f"[red]âŒ éŸ³é¢‘æå–å¤±è´¥: {e}[/red]")
        return False
def separate_vocals_with_demucs(audio_path, output_dir):
    """ä½¿ç”¨Demucsåˆ†ç¦»äººå£°"""
    try:
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(audio_path):
            rprint(f"[red]âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}[/red]")
            return None
        
        file_size = os.path.getsize(audio_path)
        rprint(f"[cyan]  ğŸ“ éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_path)} ({file_size/1024:.1f}KB)[/cyan]")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(output_dir, "demucs_temp")
        os.makedirs(temp_dir, exist_ok=True)
        rprint(f"[cyan]  ğŸ“‚ ä¸´æ—¶ç›®å½•: {temp_dir}[/cyan]")
        
        # è¿è¡ŒDemucs
        cmd = [
            'python', '-m', 'demucs.separate',
            '--two-stems=vocals',
            '-o', temp_dir,
            audio_path
        ]
        
        rprint(f"[cyan]  ğŸ¤ å¼€å§‹åˆ†ç¦»äººå£°...[/cyan]")
        rprint(f"[dim]  å‘½ä»¤: {' '.join(cmd)}[/dim]")
        
        with console.status("[yellow]ğŸ¤ åˆ†ç¦»äººå£°ä¸­...", spinner="dots"):
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        rprint(f"[cyan]  ğŸ“Š Demucsè¿”å›ç : {result.returncode}[/cyan]")
        
        if result.returncode != 0:
            rprint(f"[red]âŒ Demucsæ‰§è¡Œå¤±è´¥[/red]")
            rprint(f"[red]stderr: {result.stderr}[/red]")
            rprint(f"[red]stdout: {result.stdout}[/red]")
            return None
        
        # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
        audio_name = os.path.splitext(os.path.basename(audio_path))[0]
        rprint(f"[cyan]  ğŸ” æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶ï¼ŒéŸ³é¢‘å: {audio_name}[/cyan]")
        
        vocals_path = None
        all_files = []
        
        # æœç´¢è¾“å‡ºæ–‡ä»¶
        for root, dirs, files in os.walk(temp_dir):
            rprint(f"[dim]  æœç´¢ç›®å½•: {root}[/dim]")
            for file in files:
                full_path = os.path.join(root, file)
                all_files.append(full_path)
                rprint(f"[dim]    æ–‡ä»¶: {file}[/dim]")
                
                if 'vocals' in file.lower() and audio_name in file:
                    vocals_path = full_path
                    rprint(f"[green]  âœ“ æ‰¾åˆ°äººå£°æ–‡ä»¶: {file}[/green]")
                    break
        
        if not vocals_path:
            rprint(f"[yellow]âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„äººå£°æ–‡ä»¶[/yellow]")
            rprint(f"[yellow]æœŸæœ›åŒ…å«: 'vocals' å’Œ '{audio_name}'[/yellow]")
            rprint(f"[yellow]æ‰€æœ‰æ–‡ä»¶:[/yellow]")
            for f in all_files:
                rprint(f"[dim]  - {f}[/dim]")
            
            # å°è¯•æŸ¥æ‰¾ä»»ä½•åŒ…å«vocalsçš„æ–‡ä»¶
            for f in all_files:
                if 'vocals' in os.path.basename(f).lower():
                    vocals_path = f
                    rprint(f"[yellow]  ğŸ”„ ä½¿ç”¨å¤‡é€‰æ–‡ä»¶: {os.path.basename(f)}[/yellow]")
                    break
        
        if not vocals_path:
            rprint(f"[red]âŒ å®Œå…¨æ‰¾ä¸åˆ°äººå£°æ–‡ä»¶[/red]")
            return None
        
        # æ£€æŸ¥æ‰¾åˆ°çš„æ–‡ä»¶
        if not os.path.exists(vocals_path):
            rprint(f"[red]âŒ äººå£°æ–‡ä»¶ä¸å­˜åœ¨: {vocals_path}[/red]")
            return None
        
        vocals_size = os.path.getsize(vocals_path)
        rprint(f"[green]  âœ“ äººå£°æ–‡ä»¶å¤§å°: {vocals_size/1024:.1f}KB[/green]")
        
        if vocals_size < 1024:  # å°äº1KBå¯èƒ½æ˜¯ç©ºæ–‡ä»¶
            rprint(f"[yellow]âš ï¸ äººå£°æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½åˆ†ç¦»å¤±è´¥[/yellow]")
        
        # ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
        final_vocals_path = os.path.join(output_dir, f"{audio_name}_vocals.mp3")
        rprint(f"[cyan]  ğŸ“ ç›®æ ‡è·¯å¾„: {final_vocals_path}[/cyan]")
        
        # è½¬æ¢ä¸ºmp3æ ¼å¼
        if vocals_path.endswith('.wav'):
            rprint(f"[cyan]  ğŸ”„ è½¬æ¢WAVåˆ°MP3[/cyan]")
            convert_cmd = [
                'ffmpeg', '-i', vocals_path, 
                '-acodec', 'libmp3lame', 
                '-ab', '192k',
                final_vocals_path, '-y'
            ]
            convert_result = subprocess.run(convert_cmd, capture_output=True, text=True, timeout=60)
            
            if convert_result.returncode != 0:
                rprint(f"[red]âŒ æ ¼å¼è½¬æ¢å¤±è´¥[/red]")
                rprint(f"[red]stderr: {convert_result.stderr}[/red]")
                return None
        else:
            rprint(f"[cyan]  ğŸ“‹ å¤åˆ¶æ–‡ä»¶[/cyan]")
            import shutil
            shutil.copy2(vocals_path, final_vocals_path)
        
        # éªŒè¯æœ€ç»ˆæ–‡ä»¶
        if os.path.exists(final_vocals_path):
            final_size = os.path.getsize(final_vocals_path)
            rprint(f"[green]  âœ… äººå£°åˆ†ç¦»å®Œæˆ: {os.path.basename(final_vocals_path)} ({final_size/1024:.1f}KB)[/green]")
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                import shutil
                shutil.rmtree(temp_dir)
                rprint(f"[dim]  ğŸ§¹ æ¸…ç†ä¸´æ—¶ç›®å½•[/dim]")
            except:
                pass
            
            return final_vocals_path
        else:
            rprint(f"[red]âŒ æœ€ç»ˆæ–‡ä»¶åˆ›å»ºå¤±è´¥[/red]")
            return None
            
    except subprocess.TimeoutExpired:
        rprint(f"[red]âŒ Demucsæ‰§è¡Œè¶…æ—¶ (>300ç§’)[/red]")
        return None
    except Exception as e:
        rprint(f"[red]âŒ äººå£°åˆ†ç¦»é”™è¯¯: {e}[/red]")
        import traceback
        rprint(f"[red]è¯¦ç»†é”™è¯¯: {traceback.format_exc()}[/red]")
        return None

def detect_speech_pauses_in_segment(vocals_path):
    """æ£€æµ‹éŸ³é¢‘ç‰‡æ®µä¸­çš„äººå£°åœé¡¿"""
    speech_configs = [
        (-15, 0.05, "è¯é—´åœé¡¿(-15dB, 50ms)", "è¯é—´"),
        (-18, 0.05, "çŸ­å¥åœé¡¿(-18dB, 50ms)", "çŸ­å¥"),
        (-20, 0.05, "å¥é—´åœé¡¿(-20dB, 50ms)", "å¥é—´"),
        (-25, 0.05, "æ®µè½åœé¡¿(-25dB, 50ms)", "æ®µè½"),
        (-15, 0.1, "è¯é—´åœé¡¿(-15dB, 100ms)", "è¯é—´"),
        (-18, 0.1, "çŸ­å¥åœé¡¿(-18dB, 100ms)", "çŸ­å¥"),
        (-20, 0.1, "å¥é—´åœé¡¿(-20dB, 100ms)", "å¥é—´"),
        (-25, 0.1, "æ®µè½åœé¡¿(-25dB, 100ms)", "æ®µè½"),
        (-15, 0.15, "é•¿è¯é—´(-15dB, 150ms)", "é•¿è¯é—´"),
        (-18, 0.15, "é•¿å¥é—´(-18dB, 150ms)", "é•¿å¥é—´"),
        (-20, 0.15, "è‡ªç„¶åœé¡¿(-20dB, 150ms)", "è‡ªç„¶"),
    ]
    
    all_results = []
    
    for noise_db, min_duration, desc, pause_type in speech_configs:
        cmd = [
            'ffmpeg',
            '-i', vocals_path,
            '-af', f'silencedetect=noise={noise_db}dB:duration={min_duration}',
            '-f', 'null',
            '-',
            '-v', 'info'
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
            
            silence_periods = []
            current_silence_start = None
            
            for line in result.stderr.split('\n'):
                line = line.strip()
                
                if 'silence_start:' in line:
                    try:
                        start_part = line.split('silence_start:')[1].strip()
                        silence_start = float(start_part.split()[0])
                        current_silence_start = silence_start
                    except:
                        continue
                        
                elif 'silence_end:' in line and current_silence_start is not None:
                    try:
                        parts = line.split('silence_end:')[1]
                        
                        if '|' in parts:
                            end_part = parts.split('|')[0].strip()
                            duration_part = parts.split('silence_duration:')[1].strip()
                            silence_end = float(end_part)
                            silence_duration = float(duration_part)
                        else:
                            silence_end = float(parts.strip())
                            silence_duration = silence_end - current_silence_start
                        
                        if silence_duration >= min_duration:
                            silence_periods.append({
                                'start': current_silence_start,
                                'end': silence_end,
                                'duration': silence_duration,
                                'center': (current_silence_start + silence_end) / 2,
                                'type': pause_type
                            })
                        current_silence_start = None
                    except:
                        continue
            
            # æŒ‰åœé¡¿æ—¶é•¿åˆ†ç±»
            micro_pauses = [s for s in silence_periods if 0.05 <= s['duration'] < 0.1]
            short_pauses = [s for s in silence_periods if 0.1 <= s['duration'] < 0.2]
            medium_pauses = [s for s in silence_periods if 0.2 <= s['duration'] < 0.5]
            long_pauses = [s for s in silence_periods if s['duration'] >= 0.5]
            
            result_info = {
                'config': (noise_db, min_duration, desc, pause_type),
                'silences': silence_periods,
                'count': len(silence_periods),
                'micro': len(micro_pauses),
                'short': len(short_pauses),
                'medium': len(medium_pauses),
                'long': len(long_pauses)
            }
            all_results.append(result_info)
                
        except Exception as e:
            continue
    
    return all_results

# ==================== ä¸»è¦åŠŸèƒ½å‡½æ•° ====================
def generate_cut_plan(input_video_path, output_dir, target_interval=30):
    """
    å‡½æ•°1: ç”Ÿæˆåˆ‡åˆ†è®¡åˆ’
    è¾“å…¥é•¿è§†é¢‘ï¼Œæ¯éš”30åˆ†é’Ÿè¿›è¡Œåˆ‡åˆ†æ£€æµ‹ï¼Œè¾“å‡ºæ‰§è¡Œè®¡åˆ’
    """
    rprint(Panel.fit("[bold magenta]ğŸ¯ ç”Ÿæˆæ™ºèƒ½åˆ‡åˆ†è®¡åˆ’[/bold magenta]", border_style="magenta"))
    
    # æ£€æŸ¥æ–‡ä»¶å’Œç¯å¢ƒ
    if not os.path.exists(input_video_path):
        rprint(f"[bold red]âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_video_path}[/bold red]")
        return None
    
    if not check_demucs_installation():
        rprint("[red]âŒ Demucsæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install demucs[/red]")
        return None
    
    # è·å–è§†é¢‘ä¿¡æ¯
    total_duration = get_video_duration(input_video_path)
    if total_duration is None:
        return None
    
    rprint(f"[green]âœ“ è§†é¢‘æ–‡ä»¶[/green]: [cyan]{os.path.basename(input_video_path)}[/cyan]")
    rprint(f"[green]âœ“ è§†é¢‘æ—¶é•¿[/green]: [yellow]{format_time(total_duration)}[/yellow]")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ğŸ’¾ å®šä¹‰ä¿å­˜æ–‡ä»¶è·¯å¾„
    progress_file = os.path.join(output_dir, "cut_progress.json")
    plan_file = os.path.join(output_dir, "cut_plan.json")
    
    # è®¡ç®—æ£€æµ‹ç‚¹
    interval_seconds = target_interval * 60
    detection_points = []
    
    current_time = interval_seconds
    while current_time < total_duration:
        detection_points.append(current_time)
        current_time += interval_seconds
    
    if not detection_points:
        rprint(f"[yellow]âš ï¸ è§†é¢‘æ—¶é•¿ä¸è¶³{target_interval}åˆ†é’Ÿï¼Œæ— éœ€åˆ‡åˆ†[/yellow]")
        # è¿”å›å•æ®µè®¡åˆ’
        plan = {
            'input_video': input_video_path,
            'total_duration': total_duration,
            'target_interval': target_interval,
            'cut_points': [],
            'segments': [{
                'index': 1,
                'start': 0,
                'end': total_duration,
                'duration': total_duration,
                'cut_type': 'whole'
            }]
        }
        return plan
    
    # ğŸ”„ æ£€æŸ¥æ˜¯å¦æœ‰å·²ä¿å­˜çš„è¿›åº¦
    cut_points = []
    start_index = 0
    
    if os.path.exists(progress_file):
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            
            # éªŒè¯è¿›åº¦æ–‡ä»¶æ˜¯å¦åŒ¹é…å½“å‰ä»»åŠ¡
            if (progress_data.get('input_video') == input_video_path and 
                abs(progress_data.get('total_duration', 0) - total_duration) < 1):
                
                cut_points = progress_data.get('completed_cut_points', [])
                start_index = len(cut_points)
                
                if start_index > 0:
                    rprint(f"[green]ğŸ”„ å‘ç°å·²æœ‰è¿›åº¦: å·²å®Œæˆ {start_index}/{len(detection_points)} ä¸ªåˆ‡åˆ†ç‚¹[/green]")
                    for point in cut_points:
                        rprint(f"[dim]  âœ“ {format_time(point['target'])} -> {format_time(point['actual'])}[/dim]")
        except:
            rprint(f"[yellow]âš ï¸ æ— æ³•åŠ è½½è¿›åº¦æ–‡ä»¶ï¼Œé‡æ–°å¼€å§‹[/yellow]")
    
    rprint(f"[cyan]ğŸ“ è®¡åˆ’æ£€æµ‹ {len(detection_points)} ä¸ªåˆ‡åˆ†ç‚¹[/cyan]")
    
    # å¯¹æ¯ä¸ªæ£€æµ‹ç‚¹è¿›è¡Œåˆ†æ
    try:
        for i, target_time in enumerate(detection_points):
            # è·³è¿‡å·²å®Œæˆçš„ç‚¹
            if i < start_index:
                continue
                
            rprint(f"\n[yellow]ğŸ¯ åˆ†æåˆ‡åˆ†ç‚¹ {i+1}/{len(detection_points)} (ç›®æ ‡: {format_time(target_time)})[/yellow]")
            
            cut_point = detect_optimal_cut_point(
                input_video_path, 
                target_time, 
                total_duration, 
                output_dir, 
                i+1
            )
            
            if cut_point:
                cut_points.append(cut_point)
                rprint(f"[green]âœ… æ‰¾åˆ°åˆ‡åˆ†ç‚¹: {format_time(cut_point['actual'])} (åå·®: {cut_point['deviation']:+.1f}s)[/green]")
            else:
                # ä½¿ç”¨å¤‡é€‰ç‚¹
                fallback_point = {
                    'target': target_time,
                    'actual': target_time,
                    'deviation': 0,
                    'silence_duration': 0,
                    'silence_type': 'fallback',
                    'confidence': 'low'
                }
                cut_points.append(fallback_point)
                rprint(f"[yellow]âš ï¸ ä½¿ç”¨å¤‡é€‰ç‚¹: {format_time(target_time)}[/yellow]")
            
            # ğŸ’¾ æ¯å®Œæˆä¸€ä¸ªç‚¹å°±ä¿å­˜è¿›åº¦
            try:
                progress_data = {
                    'input_video': input_video_path,
                    'total_duration': total_duration,
                    'target_interval': target_interval,
                    'completed_cut_points': cut_points,
                    'progress': f"{len(cut_points)}/{len(detection_points)}"
                }
                with open(progress_file, 'w', encoding='utf-8') as f:
                    json.dump(progress_data, f, ensure_ascii=False, indent=2)
                rprint(f"[dim]ğŸ’¾ è¿›åº¦å·²ä¿å­˜ ({len(cut_points)}/{len(detection_points)})[/dim]")
            except:
                pass
    
    except KeyboardInterrupt:
        rprint(f"\n[yellow]âš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œè¿›åº¦å·²ä¿å­˜ï¼Œå¯é‡æ–°è¿è¡Œç»§ç»­[/yellow]")
        return None
    
    # ç”Ÿæˆæ®µè½ä¿¡æ¯
    segments = []
    
    # ç¬¬ä¸€æ®µï¼šä»å¼€å§‹åˆ°ç¬¬ä¸€ä¸ªåˆ‡åˆ†ç‚¹
    if cut_points:
        segments.append({
            'index': 1,
            'start': 0,
            'end': cut_points[0]['actual'],
            'duration': cut_points[0]['actual'],
            'cut_type': 'start'
        })
        
        # ä¸­é—´æ®µè½
        for i in range(len(cut_points) - 1):
            segments.append({
                'index': i + 2,
                'start': cut_points[i]['actual'],
                'end': cut_points[i + 1]['actual'],
                'duration': cut_points[i + 1]['actual'] - cut_points[i]['actual'],
                'cut_type': 'middle'
            })
        
        # æœ€åä¸€æ®µï¼šä»æœ€åä¸€ä¸ªåˆ‡åˆ†ç‚¹åˆ°ç»“æŸ
        segments.append({
            'index': len(cut_points) + 1,
            'start': cut_points[-1]['actual'],
            'end': total_duration,
            'duration': total_duration - cut_points[-1]['actual'],
            'cut_type': 'end'
        })
    
    # åˆ›å»ºåˆ‡åˆ†è®¡åˆ’
    plan = {
        'input_video': input_video_path,
        'total_duration': total_duration,
        'target_interval': target_interval,
        'cut_points': cut_points,
        'segments': segments
    }
    
    # ä¿å­˜è®¡åˆ’åˆ°æ–‡ä»¶
    with open(plan_file, 'w', encoding='utf-8') as f:
        json.dump(plan, f, ensure_ascii=False, indent=2)
    
    rprint(f"[green]âœ“ åˆ‡åˆ†è®¡åˆ’å·²ä¿å­˜: {plan_file}[/green]")
    
    # ğŸ§¹ å®Œæˆåæ¸…ç†è¿›åº¦æ–‡ä»¶
    try:
        if os.path.exists(progress_file):
            os.remove(progress_file)
    except:
        pass
    
    return plan

def detect_optimal_cut_point(input_video_path, target_time, total_duration, output_dir, point_index):
    """
    å‡½æ•°2: åˆ‡åˆ†æ£€æµ‹å‡½æ•° (ç®€åŒ–ç‰ˆ)
    åœ¨æŒ‡å®šæ—¶é—´ç‚¹é™„è¿‘æ£€æµ‹æœ€ä½³åˆ‡åˆ†ä½ç½®
    - ä½¿ç”¨30ç§’åˆ†æçª—å£
    - åªæ£€æµ‹-25dBä»¥ä¸‹çš„é™éŸ³
    - é€‰æ‹©çª—å£å†…æœ€åä¸€ä¸ªé™éŸ³ç‚¹ä½œä¸ºåˆ‡åˆ†ç‚¹
    """
    # å®šä¹‰åˆ†æçª—å£ï¼šç›®æ ‡æ—¶é—´å‰åå„30ç§’
    window_size = 30  # 30ç§’
    start_time = max(0, target_time - window_size)
    end_time = min(total_duration, target_time + window_size)
    analysis_duration = end_time - start_time
    
    rprint(f"[cyan]  ğŸ“Š åˆ†æçª—å£: {format_time(start_time)} - {format_time(end_time)} (Â±{window_size}s)[/cyan]")
    
    # æå–åˆ†æç‰‡æ®µ
    segment_path = os.path.join(output_dir, f"temp_segment_{point_index}.mp4")
    if not extract_video_segment(input_video_path, start_time, analysis_duration, segment_path):
        rprint(f"[yellow]  âš ï¸ æå–ç‰‡æ®µå¤±è´¥ï¼Œä½¿ç”¨ç›®æ ‡æ—¶é—´[/yellow]")
        return {
            'target': target_time,
            'actual': target_time,
            'deviation': 0,
            'silence_duration': 0,
            'silence_type': 'fallback',
            'confidence': 'low',
            'reason': 'extract_failed'
        }
    
    # æå–éŸ³é¢‘
    audio_path = os.path.join(output_dir, f"temp_audio_{point_index}.mp3")
    if not extract_audio_from_video(segment_path, audio_path):
        rprint(f"[yellow]  âš ï¸ æå–éŸ³é¢‘å¤±è´¥ï¼Œä½¿ç”¨ç›®æ ‡æ—¶é—´[/yellow]")
        if os.path.exists(segment_path):
            os.remove(segment_path)
        return {
            'target': target_time,
            'actual': target_time,
            'deviation': 0,
            'silence_duration': 0,
            'silence_type': 'fallback',
            'confidence': 'low',
            'reason': 'audio_failed'
        }
    
    # åˆ†ç¦»äººå£°
    vocals_path = separate_vocals_with_demucs(audio_path, output_dir)
    if not vocals_path:
        rprint(f"[yellow]  âš ï¸ äººå£°åˆ†ç¦»å¤±è´¥ï¼Œä½¿ç”¨ç›®æ ‡æ—¶é—´[/yellow]")
        for temp_file in [segment_path, audio_path]:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        return {
            'target': target_time,
            'actual': target_time,
            'deviation': 0,
            'silence_duration': 0,
            'silence_type': 'fallback',
            'confidence': 'low',
            'reason': 'vocals_failed'
        }
    
    # æ£€æµ‹30ç§’çª—å£å†…çš„æ‰€æœ‰é™éŸ³æ®µï¼š-25dBï¼Œæœ€å°æ—¶é•¿50ms
    rprint(f"[cyan]  ğŸ” æ£€æµ‹30ç§’çª—å£å†…çš„é™éŸ³æ®µ (-25dB, â‰¥50ms)[/cyan]")
    
    cmd = [
        'ffmpeg',
        '-i', vocals_path,
        '-af', 'silencedetect=noise=-25dB:duration=0.05',
        '-f', 'null',
        '-',
        '-v', 'info'
    ]
    
    silences = []
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        current_silence_start = None
        
        for line in result.stderr.split('\n'):
            line = line.strip()
            
            # è§£æ silence_start
            if 'silence_start:' in line:
                try:
                    start_part = line.split('silence_start:')[1].strip()
                    silence_start = float(start_part.split()[0])
                    current_silence_start = silence_start
                except Exception:
                    continue
            
            # è§£æ silence_end
            elif 'silence_end:' in line and current_silence_start is not None:
                try:
                    parts = line.split('silence_end:')[1]
                    
                    if '|' in parts:
                        end_part = parts.split('|')[0].strip()
                        duration_part = parts.split('silence_duration:')[1].strip()
                        silence_end = float(end_part)
                        silence_duration = float(duration_part)
                    else:
                        silence_end = float(parts.strip())
                        silence_duration = silence_end - current_silence_start
                    
                    if silence_duration >= 0.05:  # è‡³å°‘50ms
                        silences.append({
                            'start': current_silence_start,
                            'end': silence_end,
                            'duration': silence_duration,
                            'center': (current_silence_start + silence_end) / 2,
                            'absolute_center': start_time + (current_silence_start + silence_end) / 2,
                            'type': 'detected'
                        })
                    
                    current_silence_start = None
                    
                except Exception:
                    continue
        
    except Exception as e:
        rprint(f"[red]  âŒ é™éŸ³æ£€æµ‹å¤±è´¥: {e}[/red]")
        silences = []
    
    if not silences:
        rprint(f"[yellow]  âš ï¸ æœªæ£€æµ‹åˆ°é™éŸ³æ®µï¼Œä½¿ç”¨ç›®æ ‡æ—¶é—´[/yellow]")
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_file in [segment_path, audio_path, vocals_path]:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        return {
            'target': target_time,
            'actual': target_time,
            'deviation': 0,
            'silence_duration': 0,
            'silence_type': 'fallback',
            'confidence': 'low',
            'reason': 'no_silences'
        }
    
    rprint(f"[green]  âœ“ æ£€æµ‹åˆ° {len(silences)} ä¸ªé™éŸ³æ®µ[/green]")
    
    # æ˜¾ç¤ºæ‰€æœ‰é™éŸ³æ®µçš„ä¿¡æ¯
    for i, silence in enumerate(silences):
        rprint(f"    {i+1}. {format_time(silence['absolute_center'])} (æ—¶é•¿: {silence['duration']*1000:.0f}ms)")
    
    # é€‰æ‹©æœ€åä¸€ä¸ªé™éŸ³æ®µä½œä¸ºåˆ‡åˆ†ç‚¹
    last_silence = silences[-1]
    absolute_time = last_silence['absolute_center']
    
    best_candidate = {
        'target': target_time,
        'actual': absolute_time,
        'deviation': absolute_time - target_time,
        'silence_duration': last_silence['duration'],
        'silence_type': last_silence['type'],
        'confidence': 'high',
        'strategy': 'last_silence',
        'total_silences': len(silences)
    }
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    for temp_file in [segment_path, audio_path, vocals_path]:
        if os.path.exists(temp_file):
            os.remove(temp_file)
    
    # è¾“å‡ºç»“æœ
    rprint(f"[green]  âœ… é€‰æ‹©æœ€åä¸€ä¸ªé™éŸ³æ®µ: {format_time(absolute_time)} | "
          f"åå·®: {best_candidate['deviation']:+.1f}s | "
          f"é™éŸ³: {best_candidate['silence_duration']*1000:.0f}ms | "
          f"æ€»é™éŸ³æ®µ: {len(silences)}ä¸ª[/green]")
    
    return best_candidate

def execute_cut_plan(plan, output_dir):
    """
    å‡½æ•°3: æ‰§è¡Œåˆ‡åˆ†è®¡åˆ’
    æ ¹æ®åˆ‡åˆ†è®¡åˆ’å®é™…åˆ‡åˆ†è§†é¢‘
    """
    rprint(Panel.fit("[bold green]ğŸš€ æ‰§è¡Œè§†é¢‘åˆ‡åˆ†[/bold green]", border_style="green"))
    
    input_video = plan['input_video']
    segments = plan['segments']
    
    if not os.path.exists(input_video):
        rprint(f"[red]âŒ æºè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_video}[/red]")
        return False
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    segments_dir = os.path.join(output_dir, "segments")
    os.makedirs(segments_dir, exist_ok=True)
    
    rprint(f"[cyan]ğŸ“ è¾“å‡ºç›®å½•: {segments_dir}[/cyan]")
    rprint(f"[cyan]ğŸ¬ å¼€å§‹åˆ‡åˆ† {len(segments)} ä¸ªç‰‡æ®µ...[/cyan]")
    
    success_count = 0
    
    for segment in segments:
        segment_name = f"segment_{segment['index']:02d}.mp4"
        output_path = os.path.join(segments_dir, segment_name)
        
        rprint(f"\n[yellow]âœ‚ï¸ åˆ‡åˆ†ç‰‡æ®µ {segment['index']}: {format_time(segment['start'])} - {format_time(segment['end'])}[/yellow]")
        
        cmd = [
            'ffmpeg',
            '-i', input_video,
            '-ss', str(segment['start']),
            '-t', str(segment['duration']),
            '-c', 'copy',
            output_path,
            '-y'
        ]
        
        try:
            with console.status(f"[yellow]å¤„ç†ç‰‡æ®µ {segment['index']}...", spinner="dots"):
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                file_size = os.path.getsize(output_path) / 1024 / 1024  # MB
                rprint(f"[green]âœ… ç‰‡æ®µ {segment['index']} å®Œæˆ: {segment_name} ({file_size:.1f}MB)[/green]")
                success_count += 1
            else:
                rprint(f"[red]âŒ ç‰‡æ®µ {segment['index']} å¤±è´¥: {result.stderr}[/red]")
                
        except subprocess.TimeoutExpired:
            rprint(f"[red]âŒ ç‰‡æ®µ {segment['index']} è¶…æ—¶[/red]")
        except Exception as e:
            rprint(f"[red]âŒ ç‰‡æ®µ {segment['index']} é”™è¯¯: {e}[/red]")
    
    # ç”Ÿæˆåˆ‡åˆ†æŠ¥å‘Š
    report_file = os.path.join(output_dir, "cut_report.txt")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("è§†é¢‘åˆ‡åˆ†æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"æºè§†é¢‘: {os.path.basename(input_video)}\n")
        f.write(f"æ€»æ—¶é•¿: {format_time(plan['total_duration'])}\n")
        f.write(f"ç›®æ ‡é—´éš”: {plan['target_interval']} åˆ†é’Ÿ\n")
        f.write(f"åˆ‡åˆ†ç‚¹æ•°: {len(plan['cut_points'])}\n")
        f.write(f"ç”Ÿæˆç‰‡æ®µ: {len(segments)}\n")
        f.write(f"æˆåŠŸç‰‡æ®µ: {success_count}\n")
        f.write(f"æˆåŠŸç‡: {success_count/len(segments)*100:.1f}%\n\n")
        
        f.write("ç‰‡æ®µè¯¦æƒ…:\n")
        f.write("-" * 30 + "\n")
        for segment in segments:
            f.write(f"ç‰‡æ®µ {segment['index']:2d}: {format_time(segment['start'])} - {format_time(segment['end'])} ({format_time(segment['duration'])})\n")
    
    rprint(f"\n[green]ğŸ‰ åˆ‡åˆ†å®Œæˆ! æˆåŠŸ: {success_count}/{len(segments)}[/green]")
    rprint(f"[cyan]ğŸ“‹ æŠ¥å‘Šå·²ä¿å­˜: {report_file}[/cyan]")
    
    return success_count == len(segments)

def display_cut_plan(plan):
    """æ˜¾ç¤ºåˆ‡åˆ†è®¡åˆ’çš„è¯¦ç»†ä¿¡æ¯"""
    rprint(Panel.fit("[bold blue]ğŸ“‹ åˆ‡åˆ†è®¡åˆ’é¢„è§ˆ[/bold blue]", border_style="blue"))
    
    # åŸºæœ¬ä¿¡æ¯
    rprint(f"[green]ğŸ“ æºè§†é¢‘[/green]: {os.path.basename(plan['input_video'])}")
    rprint(f"[green]â±ï¸ æ€»æ—¶é•¿[/green]: {format_time(plan['total_duration'])}")
    rprint(f"[green]ğŸ¯ ç›®æ ‡é—´éš”[/green]: {plan['target_interval']} åˆ†é’Ÿ")
    rprint(f"[green]âœ‚ï¸ åˆ‡åˆ†ç‚¹[/green]: {len(plan['cut_points'])} ä¸ª")
    rprint(f"[green]ğŸ“¹ ç”Ÿæˆç‰‡æ®µ[/green]: {len(plan['segments'])} ä¸ª")
    
    # åˆ‡åˆ†ç‚¹è¯¦æƒ…
    if plan['cut_points']:
        rprint(f"\n[cyan]ğŸ¯ åˆ‡åˆ†ç‚¹è¯¦æƒ…:[/cyan]")
        for i, cp in enumerate(plan['cut_points']):
            confidence_color = "green" if cp.get('confidence') == 'high' else "yellow" if cp.get('confidence') == 'medium' else "red"
            rprint(f"  {i+1}. {format_time(cp['actual'])} (åå·®: {cp['deviation']:+.1f}s, ç±»å‹: {cp['silence_type']}, ç½®ä¿¡åº¦: [{confidence_color}]{cp.get('confidence', 'unknown')}[/{confidence_color}])")
    
    # æ®µè½é¢„è§ˆè¡¨æ ¼
    rprint(f"\n[cyan]ğŸ“¹ æ®µè½é¢„è§ˆ:[/cyan]")
    table = Table(show_header=True, header_style="bold magenta")
    table.add_column("ç‰‡æ®µ", style="dim", width=6)
    table.add_column("å¼€å§‹æ—¶é—´", style="cyan")
    table.add_column("ç»“æŸæ—¶é—´", style="cyan")
    table.add_column("æ—¶é•¿", style="yellow")
    table.add_column("ç±»å‹", style="green")
    
    for segment in plan['segments']:
        table.add_row(
            f"{segment['index']:02d}",
            format_time(segment['start']),
            format_time(segment['end']),
            format_time(segment['duration']),
            segment['cut_type']
        )
    
    console.print(table)

def main():
    """ä¸»å‡½æ•°ï¼šç»„è£…è°ƒç”¨é€»è¾‘"""
    parser = argparse.ArgumentParser(description="æ™ºèƒ½è§†é¢‘åˆ‡åˆ†å·¥å…·")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥è§†é¢‘æ–‡ä»¶")
    parser.add_argument("--output", "-o", required=True, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--interval", "-t", type=int, default=30, help="ç›®æ ‡åˆ‡åˆ†é—´éš”ï¼ˆåˆ†é’Ÿï¼‰")
    parser.add_argument("--auto", "-a", action="store_true", help="è‡ªåŠ¨æ‰§è¡Œï¼Œä¸è¯¢é—®ç¡®è®¤")
    
    args = parser.parse_args()
    
    # æ­¥éª¤1: ç”Ÿæˆåˆ‡åˆ†è®¡åˆ’
    rprint("[bold cyan]æ­¥éª¤ 1/3: ç”Ÿæˆåˆ‡åˆ†è®¡åˆ’[/bold cyan]")
    plan = generate_cut_plan(args.input, args.output, args.interval)
    
    if not plan:
        rprint("[red]âŒ ç”Ÿæˆåˆ‡åˆ†è®¡åˆ’å¤±è´¥[/red]")
        return
    
    # æ­¥éª¤2: æ˜¾ç¤ºè®¡åˆ’å¹¶ç¡®è®¤
    rprint(f"\n[bold cyan]æ­¥éª¤ 2/3: é¢„è§ˆåˆ‡åˆ†è®¡åˆ’[/bold cyan]")
    display_cut_plan(plan)
    
    # è¯¢é—®ç”¨æˆ·ç¡®è®¤
    if not args.auto:
        if not Confirm.ask("\n[bold yellow]æ˜¯å¦ç¡®è®¤æ‰§è¡Œåˆ‡åˆ†è®¡åˆ’?[/bold yellow]"):
            rprint("[yellow]âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ[/yellow]")
            return
    
    # æ­¥éª¤3: æ‰§è¡Œåˆ‡åˆ†
    rprint(f"\n[bold cyan]æ­¥éª¤ 3/3: æ‰§è¡Œè§†é¢‘åˆ‡åˆ†[/bold cyan]")
    success = execute_cut_plan(plan, args.output)
    
    if success:
        rprint(Panel(
            "[bold green]ğŸ‰ è§†é¢‘åˆ‡åˆ†å®Œæˆï¼[/bold green]\n\n"
            f"â€¢ æºè§†é¢‘: {os.path.basename(plan['input_video'])}\n"
            f"â€¢ ç”Ÿæˆç‰‡æ®µ: {len(plan['segments'])} ä¸ª\n"
            f"â€¢ è¾“å‡ºç›®å½•: {args.output}/segments\n"
            f"â€¢ åˆ‡åˆ†æŠ¥å‘Š: {args.output}/cut_report.txt",
            title="âœ¨ å®Œæˆ",
            border_style="green"
        ))
    else:
        rprint("[red]âŒ è§†é¢‘åˆ‡åˆ†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯[/red]")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        main()
    else:
        # ç›´æ¥è°ƒç”¨ç¤ºä¾‹
        input_video = "/Users/luogaiyu/code/VideoLingo/videos/Learn Solidity Smart Contract Development ï½œ Full 2024 Cyfrin Updraft Course.webm"
        output_directory = "/Users/luogaiyu/code/VideoLingo/output/smart_cut_test"
        
        # æ­¥éª¤1: ç”Ÿæˆåˆ‡åˆ†è®¡åˆ’
        rprint("[bold cyan]æ­¥éª¤ 1/3: ç”Ÿæˆåˆ‡åˆ†è®¡åˆ’[/bold cyan]")
        plan = generate_cut_plan(input_video, output_directory, target_interval=30)
        
        if plan:
            # æ­¥éª¤2: æ˜¾ç¤ºè®¡åˆ’
            rprint(f"\n[bold cyan]æ­¥éª¤ 2/3: é¢„è§ˆåˆ‡åˆ†è®¡åˆ’[/bold cyan]")
            display_cut_plan(plan)
            
            # æ­¥éª¤3: è¯¢é—®ç¡®è®¤å¹¶æ‰§è¡Œ
            if Confirm.ask("\n[bold yellow]æ˜¯å¦ç¡®è®¤æ‰§è¡Œåˆ‡åˆ†è®¡åˆ’?[/bold yellow]"):
                rprint(f"\n[bold cyan]æ­¥éª¤ 3/3: æ‰§è¡Œè§†é¢‘åˆ‡åˆ†[/bold cyan]")
                execute_cut_plan(plan, output_directory)
            else:
                rprint("[yellow]ç”¨æˆ·å–æ¶ˆæ“ä½œ[/yellow]")